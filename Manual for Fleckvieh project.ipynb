{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "773b7930",
   "metadata": {},
   "source": [
    "## This is a general manual for the steps in analysis of Fleckvieh population\n",
    "\n",
    "Based on the manualscript created by Jasna and follow-up steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46939fbf",
   "metadata": {},
   "source": [
    "### Training data set:\n",
    "-\tCPFV = Case population Fleckvieh (recent Fleckvieh animals, born after 2010) --> around 1300 animals\n",
    "-\tRPFV = Reference population Fleckvieh (25 oldest Fleckvieh animals, born back to 1971)\n",
    "-\tRPRH = Reference population Red Holstein (25 oldest Red Holstein animals, born before 1990)\n",
    "-\tVCF-files for all 29 chromosomes (includes more animals than the ones we are interested in)\n",
    "-\tPLINK format .map, .ped and .fam-file (.fam-file includes the ~1350 animals we are interested in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f2bdad",
   "metadata": {},
   "source": [
    "#### 1.\tStep: filter the animal relevant to us (.fam-file) from the vcf-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58b32d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Install vcftools (Google: vcftools conda):\n",
    "mamba install -c bioconda vcftools\n",
    "## or\n",
    "mamba install -c conda-forge vcftools\n",
    "\n",
    "### Filter animals – example chromosome 29:\n",
    "\n",
    "vcftools --keep set1.txt --gzvcf OUT_VCF_BEAGLE4_ALL_AutoSom21b_Chr29.txt.vcf.gz --recode --stdout | gzip -c > Chrom29_set1.vcf.gz\n",
    "## --keep -->  search for the following samples\n",
    "## set1.txt --> file with animal IDs that we want to keep --> Command to establish this file (set1.txt): $ awk ‘{print $2}’ *.fam > set1.txt\n",
    "## --gzvcf --> input file as vcf.gz file\n",
    "## --stdout | gzip -c --> print output in .gz file with the name \n",
    "\n",
    "\n",
    "## Filter animals – for all chromosomes (with for-loop in #sbatch):\n",
    "vi run_vcftools.sh ### opens window where you have to write the batch-job in\n",
    "\n",
    "## THE FOLLOWING IS WHAT THE VIM FILE LOOK LIKE##########################\n",
    "\n",
    "## for our case lrz use the slrum/ in the headnode we can just ignore it\n",
    "#!/bin/bash\n",
    "#SBATCH --job-name=vcftools_all_chr\n",
    "#SBATCH --output=vcftools_all_chr.out\n",
    "#SBATCH --error=vcftools_all_chr.err\n",
    "#SBATCH --nodes=1\n",
    "#SBATCH --tasks-per-node=1\n",
    "#SBATCH --cpus-per-task=8\n",
    "#SBATCH --mem=100000\n",
    "#SBATCH --time=48:00:00\n",
    "#SBATCH --partition=base\n",
    "\n",
    "export OMP_NUM_THREADS=8\n",
    "source ~/.bashrc\n",
    "\n",
    "\n",
    "## Loop for filtering animals for all 1-29 chromosomes\n",
    "for z in {1..29}; do\n",
    "    vcftools --keep set1.txt --gzvcf OUT_VCF_BEAGLE4_ALL_AutoSom21b_Chr${z}.txt.vcf.gz --recode --stdout | gzip -c > Chrom${z}_set_rprh_cpfv.vcf.gz\n",
    "done\n",
    "\n",
    "\n",
    "## Running the bash script\n",
    "./run_vcftools.sh\n",
    "##OR\n",
    "sbatch run_vcftools.sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b1f7d5",
   "metadata": {},
   "source": [
    "### SLURM Directives:\n",
    "These lines starting with #SBATCH are directives for SLURM, a workload manager for running jobs on high-performance computing (HPC) clusters.\n",
    "\n",
    "#### 1. #!/bin/bash:\n",
    "This is the shebang line, indicating that the script should be executed with the Bash shell.\n",
    "\n",
    "#### 2. #SBATCH --job-name=vcftools_all_chr:\n",
    "This sets the name of the job. In this case, the job is named vcftools_all_chr.\n",
    "\n",
    "#### 3. #SBATCH --output=vcftools_all_chr.out:\n",
    "The output of the job (standard output) will be written to a file named vcftools_all_chr.out.\n",
    "\n",
    "#### 4. #SBATCH --error=vcftools_all_chr.err:\n",
    "If any errors occur during the job's execution, they will be written to a file named vcftools_all_chr.err.\n",
    "\n",
    "#### 5. #SBATCH --nodes=1:\n",
    "This requests one node (a computing unit in a cluster).\n",
    "\n",
    "#### 6. #SBATCH --tasks-per-node=1:\n",
    "This requests one task (or process) to run on the node.\n",
    "\n",
    "#### 7. #SBATCH --cpus-per-task=8:\n",
    "This specifies that each task should use 8 CPUs (or cores). It means that the task is multi-threaded and will utilize 8 CPUs.\n",
    "\n",
    "#### 8. #SBATCH --mem=100000:\n",
    "This requests 100,000 MB (100 GB) of memory for the job.\n",
    "\n",
    "#### 9. #SBATCH --time=48:00:00:\n",
    "This requests a maximum runtime of 48 hours for the job. If the job takes longer than 48 hours, SLURM will stop it.\n",
    "\n",
    "#### 10. #SBATCH --partition=base:\n",
    "This specifies that the job should run on the \"base\" partition or queue within the cluster. Different partitions might have different priorities, resources, or runtime limits."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3acf6b",
   "metadata": {},
   "source": [
    "### Job execution\n",
    "1. export OMP_NUM_THREADS=8:\n",
    "This sets the environment variable OMP_NUM_THREADS to 8, which is useful for multi-threaded programs. It tells the program (in this case, vcftools) to use 8 threads.\n",
    "\n",
    "2. source ~/.bashrc:\n",
    "This sources the user's .bashrc file, which loads environment variables and paths defined in that file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70b1cc0",
   "metadata": {},
   "source": [
    "#### 2.\tStep: Establish a .map-file for each chromosome (necessary as input file for the program hap-IBD) – as  batch-job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a37008",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in {1..29}; do\n",
    "    zcat Chrom${i}_set_rprh_cpfv.vcf.gz | awk '$o!~/#/{print $1, $3, $2/1000000, $2}' > Chrom${i}_set_rprh_cpfv.map\n",
    "done\n",
    "\n",
    "## zcat decompresses the file Chrom1_set_rprh_cpfv.vcf.gz, Chrom2_set_rprh_cpfv.vcf.gz, etc., up to chromosome 29.\n",
    "\n",
    "## $o!~/#/: This is a condition to skip lines that start with # (i.e., header lines in the VCF file). \n",
    "## It processes only lines that don't begin with # (non-comment lines).\n",
    "\n",
    "## The output from awk is redirected to a new file called Chrom${i}_set_rprh_cpfv.map. \n",
    "## For each chromosome, it creates a separate .map file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e20c9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "## .map file format like\n",
    "##Chrom1_set_rprh_cpfv.map as example\n",
    "\n",
    "1 Hapmap43437-BTA-101873 0.776231 776231\n",
    "1 ARS-BFGL-NGS-16466 0.90781 907810\n",
    "1 Hapmap34944-BES1_Contig627_1906 1.03256 1032564\n",
    "1 BTA-07251-no-rs 1.0735 1073496\n",
    "1 ARS-BFGL-NGS-98142 1.11039 1110393\n",
    "1 Hapmap53946-rs29015852 1.15076 1150763\n",
    "1 BFGL-NGS-114208 1.16705 1167048\n",
    "1 ARS-BFGL-NGS-66449 1.20483 1204825\n",
    "1 ARS-BFGL-BAC-32770 1.56654 1566539\n",
    "1 ARS-BFGL-NGS-65067 1.60494 1604940"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430f5e82",
   "metadata": {},
   "source": [
    "#### 3.\tStep: run hap-IBD – as batch-job and generate ser_rprh_cpfv files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56789e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in {1..29}; do\n",
    "    hap-ibd gt=Chrom${i}_set_rprh_cpfv.vcf.gz map=Chrom${i}_set_rprh_cpfv.map out=Chrom${i}_set_rprh_cpfv;\n",
    "done\n",
    "\n",
    "##hap-ibd is the program used to infer identity-by-descent (IBD) segments in a population or genomic dataset, based on genotype data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd70d95",
   "metadata": {},
   "source": [
    "#### 4.\tStep: sort the hap-IBD output – as batch-job (with for-loop; for big datasets parallelization is helpful):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e09042",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in {1..29}; do \n",
    "    zcat Chrom${i}_set_rprh_cpfv.ibd.gz | sort -g -k6,6 -k7,7 | gzip -c > Chrom${i}_set_rprh_cpfv_sorted.ibd.gz; \n",
    "done\n",
    "\n",
    "## sort -g --> general numeric sort in numerical order (0,1,…,99,100)\n",
    "## -k6,6 --> speficify the key column to sort by (column 6 in this case)\n",
    "## -k7,7 --> if the values on column 6 is the same, sort by column 7\n",
    "\n",
    "### The file looks like\n",
    "zcat Chrom1_set_rprh_cpfv_sorted.ibd.gz | head\n",
    "\n",
    "0359411 2       ASR48555        1       1       776231  5147933 4.372\n",
    "0359411 2       FV2147  1       1       776231  5147933 4.372\n",
    "AA0000  1       BB0000  2       1       776231  5147933 4.372\n",
    "AA0000  1       BC0000  2       1       776231  5147933 4.372\n",
    "AA0000  1       BD0000  2       1       776231  5147933 4.372\n",
    "AA0000  1       BD0022  2       1       776231  5147933 4.372\n",
    "AA0000  1       BE0000  2       1       776231  5147933 4.372\n",
    "AA0000  1       DA0000  1       1       776231  5147933 4.372\n",
    "AA0000  1       DA0222  1       1       776231  5147933 4.372\n",
    "AA0000  1       FA0000  1       1       776231  5147933 4.372\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f363e659",
   "metadata": {},
   "source": [
    "#### 5.\tStep: run python script (plot_ibd.py) for all chromosomes – as batch-job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe16fef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in {1..29}; do \n",
    "    python plot_ibd.py Chrom${i}_set_rprh_cpfv_sorted.ibd.gz rprh_pop.txt cpfv_pop.txt Chrom${i}_set_rhrp_cpfv.map Chrom${i}_set_rprh_cpfv.out; \n",
    "done\n",
    "\n",
    "## plot_ibd.py --> python script\n",
    "## Chrom${i}_set_rprh_cpfv_sorted.ibd.gz --> input file: ibd_output_sorted\n",
    "## rprh_pop.txt --> source population: reference population RH\n",
    "## cpfv_pop.txt --> destination population: case population FV\n",
    "##Chrom${i}_set_rhrp_cpfv.map --> SNP-map-file\n",
    "## Chrom${i}_set_rprh_cpfv.out --> output file\n",
    "\n",
    "\n",
    "## in my case, I used the following commands to run in the project diretory\n",
    "BASE_DIR=\"/home/maulik/data/Shared/Maulik/projects/fleckvieh_project\"\n",
    "\n",
    "parallel -j 29 python $BASE_DIR/ibdtool/plot_ibd.py $BASE_DIR/hapibd/set_sorted/Chrom{1}_set_rprh_cpfv_sorted.ibd.gz $BASE_DIR/original_data/source_pop_rh.txt $BASE_DIR/original_data/recent_pop_fv_neu.txt $BASE_DIR/hapibd/map_files/Chrom{1}_set_rprh_cpfv.map $BASE_DIR/jade_test/set_out/Chrom{1}_set_rprh_cpfv.out sum_hap ::: {1..29}\n",
    "### change the number from 29 to 16 due to the number of avaliable GPUs.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##based on plot_ibd.py, two files generated\n",
    "## Chrom${i}_num_hap.txt\n",
    "The output contains SNP positions along with the number of haplotypes overlapping each SNP position\n",
    "<position> <num_haplo>\n",
    "\n",
    "## Chrom${i}_sum_anc.txt\n",
    "\n",
    "The output contains two main pieces of information:\n",
    "\n",
    "The overall difference between the maximum and minimum SNP coordinates.\n",
    "The sum of haplotype window lengths for each sample.\n",
    "\n",
    "<sample> <total_haplotype_length>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b78bbfc",
   "metadata": {},
   "source": [
    "#### This is the step to generate how many haplotypes counts are in IBD with RH populations by chromosomes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7de7736",
   "metadata": {},
   "source": [
    "#### 6.\tStep: add chromosome number to all output files – as batch-job:\n",
    "For each chromosome i, the script processes the file Chrom${i}_set_rprh_cpfv.out using awk to:\n",
    "\n",
    "- Add the chromosome number as the first column.\n",
    "\n",
    "- Extract the first and second columns from the original file.\n",
    "\n",
    "- It writes the output to a new file Chrom${i}_rprh_cpfv_with_chrom_id.out, where the chromosome ID is included as the first column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb9d59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in {1..29}; do \n",
    "    awk -v Chrom=$i '{print Chrom, $1, $2}' Chrom${i}_set_rprh_cpfv.out > Chrom${i}_rprh_cpfv_with_chrom_id.out; \n",
    "done\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee012d8",
   "metadata": {},
   "source": [
    "#### 7.\tStep: merge all the output files of plot_ibd.py and sort them in order to see which chromosome has the highest number of IBDs shared with RH:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2825e0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat Chrom{1..29}_rprh_cpfv_with_chrom_id.out | sort -g -r -k3,3 | head\n",
    "\n",
    "## The merged_sorted_output file looks like this:\n",
    "8 107482423 23938\n",
    "8 107445396 23937\n",
    "8 108463394 23935\n",
    "8 108535138 23930\n",
    "8 107385704 23924\n",
    "8 107547507 23919\n",
    "8 108648399 23867\n",
    "8 108603393 23865\n",
    "8 108243453 23839\n",
    "8 108879102 23838"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6edcbc",
   "metadata": {},
   "source": [
    "sort: sorts the concatenated output.\n",
    "-g: Performs a general numerical sort, so numbers are sorted based on their numeric values.\n",
    "-r: Sorts the data in reverse order, meaning it will sort in descending (largest to smallest) order.\n",
    "-k3,3: This specifies to sort by the third column. The 3,3 means to sort using only the third column.\n",
    "\n",
    "head: display the first 10 lines of the sorted data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40878dec",
   "metadata": {},
   "source": [
    "## PART II"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c5d7c9",
   "metadata": {},
   "source": [
    "Try to generate `sum_anc.txt` file too but change the sixth argument in `plot_ibd.py` than `sum_hap`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f358b81",
   "metadata": {},
   "source": [
    "#### Step 1 create input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5279f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel -j 16 python prepare_input.py Chrom{1}_set_rprh_cpfv_sorted.ibd.gz source_pop_rh.txt recent_pop_fv_neu.txt chrom{1} ::: {1..29}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eceb5367",
   "metadata": {},
   "source": [
    "The script prepares input data for each chromosome and make a order to decrease the computation loads\n",
    "\n",
    "This Python script processes genomic data, specifically focusing on identifying shared Identity-By-Descent (IBD) segments between source and target populations or samples. The script takes several input files, processes them, and outputs a sorted list of IBD segments between specified populations.\n",
    "\n",
    "#### Rearrange the data:\n",
    "when the second column is the source data, Specifically, it creates a list (n_line) that holds the values: source sample, source haplotype, target sample, target haplotype, chromosome, start, and end positions (columns 0, 1, 2, 3, 4, 5, 6).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4348e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### generated files look like: chrom7_target_sample_sorted.txt\n",
    "### RH, RH_hap, FL, FL_hap, chrom, starting snp, ending snp\n",
    "\n",
    "source_sample,ss_hap,target_sample,ts_hap,chrom,start,end\n",
    "FV0001,2,0359411,2,7,386109,7467822\n",
    "DA0222,2,ASR00017,2,7,386109,16345831\n",
    "DA0000,2,ASR00017,2,7,386109,16462754\n",
    "HF0619,2,ASR00017,2,7,386109,16462754\n",
    "HF0079,1,ASR00017,2,7,2546807,7841810\n",
    "HF0087,2,ASR00017,2,7,2546807,7841810\n",
    "KI-GT3037,2,ASR00017,2,7,2546807,7841810\n",
    "RH117,2,ASR00017,2,7,16269013,27046365\n",
    "EA0000,2,ASR00017,2,7,26940967,40388364\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcaef0f",
   "metadata": {},
   "source": [
    "#### Step 2 merge overlap within each sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c7971",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel -j 29 python merge_hap.py chrom{1}_target_sample_sorted.txt chrom{1}_pre_hap.csv ::: {1..29}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bea7fd9",
   "metadata": {},
   "source": [
    "This step merges overlapping regions in haplotype data within each sample, chromosome by chromosome. Generated file after this step:\n",
    "`chrom{i}_pre_hap.csv`\n",
    "\n",
    "animal information and haplotype information are merged and all rh_hap in IBD with fl_hap is listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5a8d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "example: `chrom7_pre_hap.csv`\n",
    "\n",
    "fl_hap,start,end,rh_hap\n",
    "ASR23942_2,386109,4505086,CC0000_1:386109-4505086 HF0799_1:386109-4505086 KI-GT3046_2:386109-4505086 RH103_1:386109-4505086 RH105_1:386109-4505086\n",
    "ASR29342_1,386109,4505086,CC0000_1:386109-4505086 HF0799_1:386109-4505086 KI-GT3046_2:386109-4505086 RH103_1:386109-4505086 RH105_1:386109-4505086\n",
    "ASR29620_1,386109,4505086,CC0000_1:386109-4505086 HF0799_1:386109-4505086 KI-GT3046_2:386109-4505086 RH103_1:386109-4505086 RH105_1:386109-4505086\n",
    "FV1897_1,386109,4505086,HF0684_2:386109-4505086 RH150_1:386109-4505086 RH150_2:386109-4505086 RR0001_2:386109-4505086\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de7e86e",
   "metadata": {},
   "source": [
    "#### Step 3 Infer haplotype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac223417",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallel -j 29 python generate_hap_info.py chrom{1}_pre_hap.csv chrom{1} ::: {1..29}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac154c87",
   "metadata": {},
   "source": [
    "This step generates three files for each chromosome:\n",
    "`chrom1_hap_count_info.txt` --> Counts of source and target haplotypes.\n",
    "`chrom1_tar_hap_info.txt` --> Information about target haplotypes.\n",
    "`chrom1_source_hap_info.txt` --> Information about source haplotypes.\n",
    "\n",
    "from the file `chrom1_pre_hap.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576c10ca",
   "metadata": {},
   "source": [
    "#### Step 4 Generate plot for haplotype frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bff42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR=\"/home/maulik/data/Shared/Maulik/projects/fleckvieh_project\"\n",
    "\n",
    "parallel -j 16 python $BASE_DIR/jade_test/hapibd-pytools/plot_haplo_freq.py $BASE_DIR/jade_test/chrom{1}_tar_hap_info.txt chrom{1}_source_hap_info.txt $BASE_DIR/hapibd/map_files/Chrom{1}_set_rprh_cpfv.map chrom{1} ::: {1..29}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d12372",
   "metadata": {},
   "source": [
    "This step generates histogram (Bokeh plot) which counts the total number of FL haplotypes in IBD with RH haplotypes "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a43e827",
   "metadata": {},
   "source": [
    "#### Step 5 Generate plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048c8745",
   "metadata": {},
   "outputs": [],
   "source": [
    "python $BASE_DIR/jade_test/hapibd-pytools/plot_haplo_stack.py $BASE_DIR/jade_test/chrom1_source_hap_info.txt 5 hap368 chrom1_tar_hap_info.txt 3300 chrom1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df857ed5",
   "metadata": {},
   "source": [
    "The script expects six command-line arguments:\n",
    "\n",
    "`source_hap_f`: Path to the source haplotype file.\n",
    "\n",
    "`num_source_hap`: Number of source haplotypes. (maximum 65 animals so usually we set to 5)\n",
    "\n",
    "`hap_id`: Haplotype ID.\n",
    "\n",
    "`tar_hap_f`: Path to the target haplotype file.\n",
    "\n",
    "`num_tar_hap`: Number of target haplotypes. (should not exceed the number in the column chrom{i}_hap_count_info.txt$count_of_tar_hap)\n",
    "\n",
    "`out_prefix`: Prefix for the output file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612ebfbe",
   "metadata": {},
   "source": [
    "The plot generates an **interactive stacked line plot** using the Bokeh library. The plot visualizes haplotype data, where each line represents a haplotype segment, and the segments are stacked vertically. \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
